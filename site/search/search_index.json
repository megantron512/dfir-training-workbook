{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the Datadog Cloud DFIR Training!","text":"<p>In this week's training we will be learning how to investigate cloud-based incidents. Throughout the training you will have the opportunity to get hands-on experience by working through a series of labs. Some of these labs will be focused on individual techniques while some will present an end-to-end attack scenario.</p>"},{"location":"aws/aws_ransomware/","title":"Ransomware in AWS","text":""},{"location":"aws/aws_ransomware/#background","title":"Background","text":"<p>SIRT has received an alert about an external KMS key being used to encrypt resources. For the sake of this lab, no signal was generated, but if it had been, it would have been triggered by this GenerateDataKey event.    </p>"},{"location":"aws/aws_ransomware/#logs","title":"Logs","text":"<p>The logs for this lab can be access via this link: Ransomware in AWS Logs.</p> <p>Note</p> <p>Since the sandbox infrastructure was used for lab development, if you do not limit your searches to account ID <code>711387092967</code>, setup activity for attacker resources will appear in the results. Feel free to look at the events to get familiar with different event types, but in the case of a similar incident, these events will not appear as they will be logged in attacker infrastructure.</p> <p>Note</p> <p>Due to the testing script used, the benign setup activity has the same IP as the attacker activity, which is unlikely to happen in most cloud attacks. Usually, the IP address would be a useful pivot point.</p>"},{"location":"aws/aws_ransomware/#investigation","title":"Investigation","text":"<p>Start by reviewing the triggering event and understanding what is happening. </p> What is the attacker doing based on this event? Hint <ul> <li>Search Google or generative AI to understand the <code>GenerateDataKey</code> event.  </li> <li>Look at <code>@requestParameters</code> in the <code>GenerateDataKey</code> event for more context.</li> </ul> Answer <p>This event indicates an attempt to encrypt data in AWS. The request parameters provide the following context:  </p> <ul> <li>The object that was encrypted is <code>arn:aws:s3:::financial-reports-2025-7449/accounting_data_2025.xml</code>, a file named <code>accounting_data_2025.xml</code> in an S3 bucket called <code>financial-reports-2025-7449</code>.   </li> <li>It was encrypted with a KMS key with ARN <code>arn:aws:kms:us-east-1:601427279990:key/88ab009c-12da-4b74-95b4-d051924119a5</code>. </li> </ul> What is a notable attribute of the KMS key involved in the encryption? Hint <p>Review what each part of the ARN represents. Is there anything in the key's ARN that does not match with the context of this event?</p> Answer <p>The account ID shown in the ARN (<code>601427279990</code>) is from a different account than the one in which the encryption is occuring. In this particular case, due to testing infrastructure, it is another account within Datadog. The signal logic and what would likely be observed in an attack though is a key outside of Datadog being used. </p> <p>Now that we have reviewed the triggering event, let's look at the bigger picture and find out what other activity is associated with the attacker.</p> What indicators can help us track the relevant activity? Hint <p>Since the IP address is <code>AWS Internal</code> this is not going to help. Fields like account or service are too broad and will capture benign activity. Request and event IDs are going to be unique to this specific event. Consider fields that are unique enough to reduce noise from legitimate users but not too unique to limit to just this event type.</p> Answer <ul> <li>User ARN: <code>arn:aws:iam::711387092967:user/CloudOpsMonitor</code> </li> <li>KMS Key ARN: <code>arn:aws:kms:us-east-1:601427279990:key/88ab009c-12da-4b74-95b4-d051924119a5</code></li> </ul> <p>Before broadening our search to all activity from the IAM user, let's first see the full scope of the encryption activities.</p> How many files were encrypted? Gather a list of the files. Hint <p>Filter by the KMS key ARN: <code>index:cloudtrail account:711387092967 @resources.ARN:\"arn:aws:kms:us-east-1:601427279990:key/88ab009c-12da-4b74-95b4-d051924119a5\"</code>. Group by <code>@requestParameters.encryptionContext.aws:s3:arn</code> for a quick view of all encrypted resources. Visualize as a table and be mindful of the display limit.  </p> Answer <p>10 files were encrypted, all in the <code>financial-reports-2025-7449</code> bucket. </p> <p></p> <p>We've mentioned in training that not all S3 buckets provide data-level logging, so any write or read operations on the bucket will not be logged. Let's go look at the bucket in the AWS console quick and see if there is anything notable.</p> Besides the bad practice of storing seemingly sensitive files, is there anything notable about the files in the bucket? Hint <p>Look at the most recently modified file.</p> Answer <p>After each file is overwritten with an encrypted version of the file (Last Modified timestamps are seconds apart), a <code>RANSOM_NOTE.txt</code> is modified or created. Viewing this file reveals a ransom note that says an AWS KMS key was used to encrypt the other files and that if payment isn't made, the encryption key will be deleted after 7 days.</p> <p>At this point, we've figured out that we were the target of a ransomware attack where an external KMS key was used to encrypt all the files in our bucket. To better understand the sequence of events that led to this, let's broaden our search to include all activity by the <code>CloudOpsMonitor</code> IAM user.</p> What other actions did the <code>CloudOpsMonitor</code> IAM user take? Hint <p>Search based on the username <code>CloudOpsMonitor</code> and group by <code>@evt.name</code>.</p> Answer <p>Along with the previously-investigated <code>GenerateDataKey</code> action, the IAM account was also used to perform the following actions:   </p> <ul> <li><code>DescribeTrails</code> </li> <li><code>StopLogging</code> </li> <li><code>PutUserPolicy</code> </li> <li><code>GetTrailStatus</code> </li> <li><code>ListBuckets</code> </li> <li><code>GetBucketVersioning</code></li> <li><code>DescribeKey</code> </li> <li><code>DescribeSnapshots</code> </li> <li><code>CopySnapshot</code> </li> <li><code>GenerateDataKeyWithoutPlaintext</code> </li> <li><code>DeleteSnapshot</code> </li> </ul> <p>Let's look through each of these events to glean some insight into what the attacker was able to do in the environment. The first events are related to CloudTrail logging.</p> What did the threat actor try to do with CloudTrail logging? What was the result? Hint <p>Look at the sequence of events and pay attention to the <code>@level</code> associated with events.</p> Answer <p>First the attacker runs <code>DescribeTrails</code>. This would allow them to retrieve a list of CloudTrails that exist in the account. The next request is to stop the logging for one of the CloudTrail's retrieved (<code>security-cloudtrail</code>). This, along with the attempt to get the Trail status after, failed due to a lack of identity-based policies allowing for those actions. This is clearly explained via Datadog in the <code>Error</code> section.</p> <p>Luckily, thanks to our IAM policies, the threat actor was unable to stop logging so we have visibility into the follow-on activities. The other event that occurs around the time of the CloudTrail is <code>PutUserPolicy</code>. </p> What is the policy that is applied supposed to do? Hint <p>Look at the <code>@requestParameters</code> of the event.</p> Answer <p>The attacker is applying a policy called <code>CloudOpsAdmins</code> to the <code>CloudOpsMonitor</code> user. The <code>@requestParameters.policyDocument</code> field shows us that the policy would allow all actions on all resources for the associated user.</p> <p>Let's move onto the bucket activity we see after the attempts to stop CloudTrail and user policy changes, but before the file encryption.</p> How many times was the <code>GetBucketVersioning</code> action taken? How many buckets was the call made against? Hint <p>Further filter the search to only include <code>@evt.name:GetBucketVersioning</code>. Count the results. Group by the bucket name to see unique count of buckets.</p> Answer <p>There are 12 <code>GetBucketVersioning</code> events targeting 6 different buckets.</p> What AWS CLI command was caused these events to be generated? Hint <p>Look at the user agent.</p> Answer <p>The user agent ends with <code>command#s3api.get-bucket-versioning</code> indicating the command executed was <code>aws s3api get-bucket-versioning</code>. We do not know if any additional parameters were passed.</p> What information can the attacker find out from running this command? How is it relevant to the threat actor's attack? Hint <p>Look up the documentation for the <code>GetBucketVersioning</code> event or <code>get-bucket-versioning</code> CLI command.</p> Answer <p>This command returns the versioning state and MFA Delete status of an S3 bucket. If versioning is enabled, this makes it much more challenging to prevent the victim from being able to recover their files, since applying encryption does not retroactively encrypt old versions of files (it just creates a new version that is encrypted). MFA Delete being enabled prevents the attacker from being able to change versioning settings or permanently delete the old versions of the files without a MFA code.</p> <p>Now we will look at the activity happening after the encrytion activity that we started from. Specifically, we are going to look at the snapshot \"write\" events.</p> How many snapshots were copied? What seems to be the threat actor's intent with these actions Hint <p>Look at API documentation to understand this event. Look at <code>@requestParameters</code> in the events for more context.</p> Answer <p>There are 4 snapshots that are copied. The threat actor appears to be attempting to encrypt the snapshots in the account using the same KMS key that was used for encrypting the buckets.</p> Which snapshots were deleted? Hint <p>Filter to the <code>DeleteSnaphot</code> events and group by <code>@requestParameters.snapshotId</code>.</p> Answer <p>The following two snapshots are deleted: - <code>snap-09336c08a16457168</code> - <code>snap-0a5c7f52ffd2db5da</code> </p> What events may explain why 4 snapshots were copied but only 2 were deleted? Hint <p>Look at failed events around this timeframe.</p> Answer <p>There are two <code>GenerateDataKeyWithoutPlaintext</code> error events. While there are no details on the snapshot the key was being generated for, logic would indicate that two of the snapshots were not able to be copied and encrypted, and thus the originals were not deleted by the threat actor in their destructive actions. </p> <p>Based on what we observed at the start of our investigation, there is something missing from the logs...</p> What activity is missing from the logs that we know happened? Hint <p>Revisit what we found in the bucket when we logged into the console.</p> Answer <p>The ransom note was created in the bucket but there is no evidence of that upload occurring. If you visit the bucket in the console, look at the <code>Server access logging</code> and <code>AWS CloudTrail data events</code> and you'll see there's no access or data events enabled, meaning we only will see management events. </p> <p>Note: This information can also be found directly in Datadog via the Resource Catalog based on the <code>logging_enabled</code> key in Resource Info.</p> <p>If those events are missing, maybe there are other events that could be missing too. Let's review the IAM user's permissions to see what other unlogged actions could've occurred.</p> What permissions does the user have that would not have been logged if they did occur? Hint <p>Go to the AWS console and look at the user in IAM.</p> Answer <p>There are two policies attached to this user. <code>CloudOpsAdmins</code> is the one we investigated as it was added by the attacker. The only existing policy from before the attack that is attached to this user is <code>CloudOpsS3Access</code>. Along with the observed management plane events, the user had the ability to <code>GetObject</code>, <code>PutObject</code>, or <code>CopyObject</code> in S3. This means that the attacker could have downloaded or copied the data without us having a way to find out. They could have also uploaded additional files elsewhere in the account, which would require a manual audit of each bucket for recent uploads.</p> <p>At this point, we've got a good feel for the flow of the attack. The threat actor did reconnaisance searching for buckets in the account, checked which accounts had versioning/MFA delete enabled, chose a target bucket to encrypt, and left behind a ransom note. We still don't know how the attacker gained access to the IAM account though.</p> How did the attacker authenticate in order to perform these actions? Hint <p>Look at the accessKeyId used for the <code>ListBuckets</code> and <code>GetBucketVersioning</code> events.</p> Answer <p>The access key ID associated with the user identity is <code>AKIA2LIPZS7T27U6CQ24</code>. As discussed when we broke down access key ID prefixes, the <code>AKIA</code> prefix indicates an access key is being used.</p> <p>The challenge at this point is there isn't really any evidence of how the attacker got ahold of the access key. Most often threat actors steal keys that are accidentally leaked in code repositories, but it could have also been stolen from a user's laptop or cloud storage. Unless an alert from AWS or Datadog tells us an API key is leaked, the exact source of the leak is not clear. The best we can do is uncover who created the key for this <code>CloudOpsMonitor</code> account and see where the key has been shared. </p> Who created the access key that has been compromised? Hint <p>Search for the event name associated with access key creation that also contains a field (the response elements) with the identified key.</p> Answer <p>The <code>CreateAccessKey</code> event shows that <code>megan.fonseca@datadoghq.com</code> created the access key for the account.   </p> <p>Note: In this case the timestamps and IP and user agent align due to how the attack simulation was executed. In a real incident you might need to look further back in the logs to find the access key creation event and it's likely to have less overlap with the attacker behavior.</p>"},{"location":"aws/lab1/","title":"Lab 1: AWS Authentication at Datadog","text":"<p>This lab is to begin understanding what authentication looks like in the logs when users accesss AWS using SSO. </p> <p>Before walking through the questions below, navigate to the AWS access portal and search for the <code>datadog-dfir-training-2025</code> account. Access it using the <code>security-admin</code> role. Within a few minutes, associated logs should be generated and shipped to the Datadog.</p>"},{"location":"aws/lab1/#goal","title":"Goal","text":"<p>The primary goal of this lab is to identify all event types that are generated when a Datadog user signs in with SSO. The upcoming slides in the training will go into detail about these events, but see what you can find yourself before we cover any gaps! </p> <p>If you think you've identified all relevant log entries, as a bonus challenge, identify other types of authentication that are occuring and notable properties associated with those events that could assist in investigating malicious activity. </p>"},{"location":"azure/azure_priv_esc/","title":"Azure Privilege Escalation","text":""},{"location":"azure/azure_priv_esc/#background","title":"Background","text":"<p>SIRT has received a Azure AD member assigned Global Administrator role in the Security Research Datadog Org that has been determined to be suspicious/malicious. Investigate the signal and determine the extent of the threat actor's activity.</p>"},{"location":"azure/azure_priv_esc/#logs","title":"Logs","text":"<p>The timestamps for searches can be access via this link in the Security Research Datadog org: Azure Logs. Further filters based on the originating signal will be required to narrow down the relevant activity.</p>"},{"location":"azure/azure_priv_esc/#investigation","title":"Investigation","text":"<p>Start by reviewing the triggering event and understanding what is happening. </p> Which user was granted the global admin role? Hint <p>Look at target resources to find the context of what changes were made.</p> Answer <p><code>@properties.targetResources.userPrincipalName</code> tells us that <code>devindeveloper@pdedatadogoutlook.onmicrosoft.com</code> was granted global admin privileges.</p> What field gives us some insight into how the role was granted? Hint <p>Look for an indication the program leveraged to perform these actions.</p> Answer <p>Based on <code>@properties.additionalDetails</code> the user agent associated with this request is <code>python-requests/2.23.0</code>. This tells us that the python requests library was used, indicating the attacker is likely executing a script to make requests to the API.</p> Which principal is responsible for granting the global admin role? Hint <p>Look at the user associated with the event.</p> Answer <p><code>DFIR Training - Top Dog Role Management</code> is the user that executed the action to grant the admin role. </p> <p>We know the principal performing the suspicious activity so let's see what other events can be tied to the user. </p> What other events are present for the principal? Hint <p>Execute a new search that focuses on Azure logs for the user <code>DFIR Training - Top Dog Role Management</code>.</p> Answer <p>There are two additional events tied to this principal, both are sign-in events.</p> What additional evidence seen in both of these events supports our finding that Python scripts may be in use by the threat actor? Hint <p>Look for additional references to Python.</p> Answer <p>The <code>@properties.authenticationProcessingDetails</code> field indicates that the authentication library that processed this request is MSAL Python.</p> What additional evidence seen in both of these events supports our finding that Python scripts may be in use by the threat actor? Hint <p>Look for additional references to Python.</p> Answer <p>The <code>@properties.authenticationProcessingDetails</code> field indicates that the authentication library that processed this request is MSAL Python.</p> What is the key difference between the two sign-in events that indicates why both events are present in a short period? Hint <p>Focus on the resource associated with the authentication.</p> Answer <p>The <code>@properties.resourceDisplayName</code> field is different between the events. One is associated with <code>Azure Resource Manager</code> and the other is associated with <code>Graph API</code>.</p> <p>We've reviewed all the activity tied to this service principal as the initiating actor but are still missing a lot of context. Let's broaden our search to find the presence of that principal in any field. </p> What is the earliest event that references the service principal? Hint <p>Filter by <code>*:DFIR Training - Top Dog Role Management</code> and look at the timestamps to identify earliest event.</p> Answer <p>The first event is <code>Update service principal</code>. </p> Which user is associated with this activity? Answer <p><code>@usr.name</code> tells us <code>devindeveloper@pdedatadogoutlook.onmicrosoft.com</code> is the user performing the actions. This is interesting because before this user was the target of actions by the service prinicipal, whereas now the service principal is the target of the user.</p> What attribute differs from our previous events that provides insight into the methodology of the attacker? Hint <p>Previously Python was in usage but we see a different access vector this time.</p> Answer <p>The <code>@properties.additionalDetails</code> field indicates that the user agent is <code>Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:135.0) Gecko/20100101 Firefox/135.0</code>. This indicates that these activities are taking place via a browser vs. a script.</p> <p>This event alone does not provide a lot of additional context in its details. Let's understand the chain of events associated with this single one.</p> What other events are directly associated with this one? Hint <p>The correlation ID can be used to tie together associated events.</p> Answer <p>2 additional events are associated with the same correlation ID:  -  <code>Update application \u2013 Certificates and secrets management</code>  - <code>Update application</code></p> <p>Let's start with the earliest of these additional events to see if we can expand our understanding of what is happening.</p> Which application was assigned a credential? Hint <p>Look at the target resource.</p> Answer <p>The application that had a secret generated is <code>DFIR Training - Top Dog Role Management</code>, which is the application that the service principal we've observed is tied to.</p> What is the display name of the key? Hint <p>Look at the target resource's modified properties.</p> Answer <p>The key description that was updated is <code>[\"[KeyIdentifier=480946b1-433f-4634-8b85-bfe21266007e,KeyType=Password,KeyUsage=Verify,DisplayName=test]\"]</code>. We can see within that string that the display name is <code>test</code>.</p> <p>??? question \"What is the other name for a key type of <code>Password</code>?\"     ??? tip \"Hint\"         Check out Microsoft's documentation for adding credentials.</p> <pre><code>??? info \"Answer\"\n    As can be seen with a Google search, at the reference link in the hint, or by going directly to the portal, there is no options to \"Add password\". The documentation mentions the following:  \n    ```\n    Sometimes called an application password, a client secret is a string value your app can use in place of a certificate to identify itself.\n    ```    \n    While the log references `password`, in the UI we would be adding a `client secret`.\n</code></pre>"},{"location":"azure/azure_priv_esc/#references","title":"References","text":""},{"location":"gcp/gcp_service_account_abuse/","title":"Default Service Account Abuse in Google Cloud","text":""},{"location":"gcp/gcp_service_account_abuse/#background","title":"Background","text":"<p>SIRT has received a Google Cloud Instance Creation via gcloud signal that has been determined to be suspicious/malicious. Investigate the signal and determine how the threat actor accessed the environment and what they did with their access.</p>"},{"location":"gcp/gcp_service_account_abuse/#logs","title":"Logs","text":"<p>The logs for this lab can be access via this link: Google Cloud Project Logs.</p> <p>Don't forget that there are some logs that don't make it to Datadog that might be worth exploring within Google Cloud Console.</p>"},{"location":"gcp/gcp_service_account_abuse/#investigation","title":"Investigation","text":"<p>Start by reviewing the signal and identifying noteworthy properties that might act as pivot points to discover related activity. </p> What indicators can help us track the relevant activity? Hint <p>Take note of the following properties:   </p> <ul> <li>IP address  </li> <li>User ID   </li> <li>Entities (related resources)  </li> </ul> Answer <ul> <li>Multiple IP addresses:<ul> <li><code>212.30.33.188</code></li> <li><code>212.30.33.202</code></li> <li><code>212.30.33.222</code></li> </ul> </li> <li>User ID: <code>research-512-serivce-account@datadog-dfir-training-2025.iam.gserviceaccount.com</code></li> <li>Related resources:   <ul> <li><code>projects/datadog-dfir-training-2025/zones/us-central1-b/instances/gpu-instance-1</code></li> <li><code>projects/datadog-dfir-training-2025/zones/us-central1-b/instances/instance-1</code></li> <li><code>projects/datadog-dfir-training-2025/zones/us-central1-b/instances/gpu-instance-2</code></li> </ul> </li> </ul> <p>A good starting point is to understand the nature of the activity is to identify what the service account was used for.</p> What actions did the service account associated with the signal take? Hint <p>Look at the event names associated with activity where the user ID is <code>research-512-serivce-account@datadog-dfir-training-2025.iam.gserviceaccount.com</code>. You can either do this with grouping by fields in Log Explorer or using Investigator against the service account. </p> Answer <p>There are 6 different event types associated with this account:   </p> <ul> <li><code>v1 compute.instances.insert</code> </li> <li><code>iam.serviceAccounts.actAs</code></li> <li><code>v1.compute.instances.get</code></li> <li><code>v1.compute.zoneOperations.wait</code> </li> <li><code>v1.compute.zones.get</code> </li> </ul> <p>Most of the associated events are read-only activity, so let's focus on the first event type: <code>v1 compute.instances.insert</code>. This indicates attempts to deploy virtual machines on Google Cloud Compute.</p> How many virtual machines were deployed and what are their instance names/IDs? Hint <p>Further filter the search for the project and service account using <code>@evt.name:v1.compute.instances.insert</code>. Look at <code>@data.protoPayload.resourceName</code> and <code>@data.resource.labels.instance_id</code> for the resource names and instance IDs.</p> Answer <ul> <li><code>instance-1</code> (<code>4005116539166594064</code>)</li> <li><code>gpu-instance-1</code> (<code>8182301838913530040</code>)</li> <li><code>gpu-instance-2</code> (<code>8506462674512996508</code>)</li> </ul> Why is there an error for one of the VM creation events? Hint <p>Look at the event with <code>status:error</code>, indicated by a red bar next to log entry. Look at the response details of that event for more context.</p> Answer <p><code>@data.protoPayload.response.error.message</code> contains the following error message:</p> <p><code>The resource 'projects/datadog-dfir-training-2025/zones/us-central1-b/instances/instance-1' already exists</code></p> <p>This indicates that the instance name (<code>instance-1</code>) is non-unique within the project.</p> <p>The logs don't provide full context. Let's look directly in Google Cloud at the virtual machines to see if there is anything interesting about the hosts that might point to attacker intent.</p> What interesting instance details could point to attacker intent? Hint <p>Look at the <code>Machine configuration</code> and <code>Custom metadata</code>.</p> Answer <p>There's two key details of interest here:  </p> <ol> <li>The host has GPUs attached. Attackers often create GPU-enabled VMs for the purpose of cryptomining.</li> <li>There is a <code>startup-script</code> key with a bash script that downloads a file from a remote host and executes it.</li> </ol> <p>Note</p> <p>The GPU usage is also present in the request details of the first <code>v1 compute.instances.insert</code> event for each instance creation. The startup script metadata implementation is not visible in the event.</p> <p>Now we've determined that the threat actor's intention was likely to leverage our compute infrastructure for cryptomining or another malicious activity, we should work backwards to determine how this service account was compromised in the first place. </p> How did the threat actor authenticate the service account? Hint <p>Look at <code>@data.protoPayload.authenticationInfo</code> in any of the logs associated with the account's activity.</p> Answer <p>The authenticationInfo field shows that there is an associated <code>serviceAccountKeyName</code>, indicating a key exists for the service account and was used to authenticate the user of the account.</p> What is the scope of access that this account has? Hint <p>Use Policy Analyzer in Google Cloud to understand the service account's permissions. </p> Answer <p>The service account has an Editor role grant on the project <code>Datadog Dfir Training 2025</code>.</p> <p>It appears the threat actor has gotten a copy of a service account key in order to leverage the account's editor permissions to carry out their attack. There's one other \"write\" event from our initial list that we haven't looked at. Let's investigate that event.</p> What account was used to pivot to the <code>research-512-serivce-account@datadog-dfir-training-2025.iam.gserviceaccount.com</code> service account? Hint <p>Look at the request details in the <code>iam.serviceAccounts.actAs</code> event.</p> Answer <p>The service account <code>222174030404-compute@developer.gserviceaccount.com</code> is associated with the <code>iam.serviceAccounts.actAs</code> event. Based on the naming convention of this account, its a Compute Engine default service account.</p> <p>A search for that service account in the <code>@usr.email</code> or <code>@usr.id</code> field will return no results. Let's see about its presence in any other fields.</p> Outside of the <code>iam.serviceAccounts.actAs</code> event investigated above, what logs include a reference to the default service account? Hint <p>Add a field for <code>*:222174030404-compute@developer.gserviceaccount.com</code>.</p> Answer <p>The only event in the results we haven't looked at doesn't have an event name and is an <code>undefined</code> service, but if you dig into the event, its a log entry associated with signal generated. It specifically is a signal for <code>Google Compute Engine service account used outside of Google Cloud</code>. If you expand the <code>Log Message</code> you can <code>View Security Signal</code>, which will provide a more readable view in Signal Explorer.</p> What events are associated with the signal? Hint <p>Don't look at the <code>Related Logs</code> section; instead view the <code>@evt.name</code> list in the JSON.</p> Answer <p>Three events were tied to the signal: - <code>storage.buckets.list</code> - <code>storage.objects.list</code>  - <code>storage.objects.get</code></p> <p>Note</p> <p>Because of the log indexing and exclusion filters discussed in the training, the full list of logs is not provided, only a single sample event (<code>storage.objects.get</code> in this case).</p> <p>Since we can't see the details of the storage logs in Datadog, let's log into the Google Cloud console and use their native Log Explorer to review these events. Set your time range to 14:15 (2:15 PM) - 14:45 (2:45 PM) UTC on 3/19/2025 to ensure the expected activity is included.</p> What tool/program was used to perform the bucket-related actions? Hint <p>Use the following search to narrow down the logs: <pre><code>resource.type=\"gcs_bucket\"\nprotoPayload.authenticationInfo.principalEmail=\"222174030404-compute@developer.gserviceaccount.com\"\n</code></pre> Look at the user agent field of any of the events.</p> Answer <p>The user agent associated with the <code>requestMetadata</code> is <code>curl/8.1.2,gzip(gfe)</code>, indicating the usage of <code>curl</code> to perform the API calls to Google Cloud Storage.</p> After listing the buckets, which bucket was targeted with the <code>storage.objects.list</code> method? Hint <p>Look at the resource name in the associated event.</p> Answer <p>The targeted bucket is <code>research-512-resources</code>.</p> Which file was downloaded from the above bucket? Hint <p>Look at the resource name in a <code>storage.objects.get</code> event.</p> Answer <p>The targeted bucket is <code>research-512-service-account-creds.json</code>. Based on the name, there is a good chance this file contains credentials for the service account observed in the initial signal and is how the attacker was able to pivot.</p> <p>At this point we've figured out that the attacker used the default service account to obtain creds stored in a bucket. Those creds were then used to deploy GPU instances. The remaining unanswered question is how did the attacker gain access to the default service account. We've looked for the account being referenced in all fields in Datadog already and there were no results. Let's look across all logs in Google Cloud in case there are other logs not collected by Datadog.</p> What resource is associated with the additional event? Hint <p>Remove any other filters and field names from your search and just run a string search for <code>\"222174030404-compute@developer.gserviceaccount.com\"</code>. Look at the <code>resource</code> section of the log entry.</p> Answer <p>The associated resource is a container named <code>vulnerable-java-application-1</code> running on a cluster called <code>cluster-1</code>.   </p> What does the message tell us about how the attacker authenticated? Hint <p>Look at the message field on the aforementioned event.</p> Answer <p>The message indicates that somewhere within the container's app, the attacker was able to inject the string <code>google.com&gt;/dev/null &amp;&amp; curl -H Metadata-Flavor:Google 169.254.169.254/computeMetadata/v1/instance/service-accounts/222174030404-compute@developer.gserviceaccount.com/token</code>. This is an attempt by the attacker to query the metadata service for the token associated with the service account, which is how they were able to proceed with their next steps.</p> Did the threat actor attempt to execute any other commands? Hint <p>Search for <code>resource.labels.container_name=\"vulnerable-java-application-1\"</code> to retrieve all of the application logs.</p> Answer <p>Prior to running the curl command to get the token, the following command was executed: <code>curl -H Metadata-Flavor:Google 169.254.169.254/computeMetadata/v1/instance/service-accounts/</code>. This would have returned a list of service accounts attached to the container/cluster, which is how they got the user ID needed to retrieve the token.</p> <p>To prevent this vulnerable app from being exploited by a real threat actor, it's since been torn down. If further investigation into the container/cluster could have been performed, you would find that the vulnerable app was exposed as a service open to the world. </p> <p>To recap, the threat actor's attack path was to exploit a public container in order to query the metadata service and obtain the default service account token. This token had effective permissions (based on access scope) that allowed it to be used to query all buckets and their objects within the project. One of the buckets contained a credential file that could be used to authenticate as a service account with editor permissions at the project-level. The permissions were used to deploy GPU-enabled VMs.</p>"}]}